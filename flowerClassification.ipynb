{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from keras import applications\n",
    "\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset tf_flowers (218.21 MiB) to C:\\Users\\jn_fe\\tensorflow_datasets\\tf_flowers\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36eb6fccfa0e422d9e6b53cc09ad66f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8cdc72571744c9ba4f314c7091436e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed60fdb1f5c40fb9606bd3228764dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe8 in position 369: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\usthb\\L3\\pfe\\Learning\\scripts\\Transfer_learning_application\\flowerClassification.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/usthb/L3/pfe/Learning/scripts/Transfer_learning_application/flowerClassification.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data , info \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mtf_flowers\u001b[39;49m\u001b[39m\"\u001b[39;49m, as_supervised\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, with_info\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/usthb/L3/pfe/Learning/scripts/Transfer_learning_application/flowerClassification.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m info\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py:52\u001b[0m, in \u001b[0;36mdisallow_positional_args.<locals>.disallow_positional_args_dec\u001b[1;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m _check_no_positional(fn, args, ismethod, allowed\u001b[39m=\u001b[39mallowed)\n\u001b[0;32m     51\u001b[0m _check_required(fn, kwargs)\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py:300\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m    299\u001b[0m   download_and_prepare_kwargs \u001b[39m=\u001b[39m download_and_prepare_kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m--> 300\u001b[0m   dbuilder\u001b[39m.\u001b[39mdownload_and_prepare(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdownload_and_prepare_kwargs)\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m as_dataset_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m   as_dataset_kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py:52\u001b[0m, in \u001b[0;36mdisallow_positional_args.<locals>.disallow_positional_args_dec\u001b[1;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m _check_no_positional(fn, args, ismethod, allowed\u001b[39m=\u001b[39mallowed)\n\u001b[0;32m     51\u001b[0m _check_required(fn, kwargs)\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:285\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, download_dir, download_config)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39mwith\u001b[39;00m file_format_adapter\u001b[39m.\u001b[39mincomplete_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir) \u001b[39mas\u001b[39;00m tmp_data_dir:\n\u001b[0;32m    282\u001b[0m   \u001b[39m# Temporarily assign _data_dir to tmp_data_dir to avoid having to forward\u001b[39;00m\n\u001b[0;32m    283\u001b[0m   \u001b[39m# it to every sub function.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m   \u001b[39mwith\u001b[39;00m utils\u001b[39m.\u001b[39mtemporary_assignment(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_data_dir\u001b[39m\u001b[39m\"\u001b[39m, tmp_data_dir):\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m    286\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[0;32m    287\u001b[0m         download_config\u001b[39m=\u001b[39;49mdownload_config)\n\u001b[0;32m    289\u001b[0m     \u001b[39m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     \u001b[39m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     \u001b[39m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     \u001b[39m# when reading from package data.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \n\u001b[0;32m    294\u001b[0m     \u001b[39m# Update the DatasetInfo metadata by computing statistics from the data.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m     \u001b[39mif\u001b[39;00m (download_config\u001b[39m.\u001b[39mcompute_stats \u001b[39m==\u001b[39m download\u001b[39m.\u001b[39mComputeStatsMode\u001b[39m.\u001b[39mSKIP \u001b[39mor\u001b[39;00m\n\u001b[0;32m    296\u001b[0m         download_config\u001b[39m.\u001b[39mcompute_stats \u001b[39m==\u001b[39m download\u001b[39m.\u001b[39mComputeStatsMode\u001b[39m.\u001b[39mAUTO \u001b[39mand\u001b[39;00m\n\u001b[0;32m    297\u001b[0m         \u001b[39mbool\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mtotal_num_examples)\n\u001b[0;32m    298\u001b[0m        ):\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:946\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, download_config):\n\u001b[0;32m    945\u001b[0m   \u001b[39m# Extract max_examples_per_split and forward it to _prepare_split\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m   \u001b[39msuper\u001b[39;49m(GeneratorBasedBuilder, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m    947\u001b[0m       dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[0;32m    948\u001b[0m       max_examples_per_split\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_examples_per_split,\n\u001b[0;32m    949\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:804\u001b[0m, in \u001b[0;36mFileAdapterBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39m# Generating data for all splits\u001b[39;00m\n\u001b[0;32m    803\u001b[0m split_dict \u001b[39m=\u001b[39m splits_lib\u001b[39m.\u001b[39mSplitDict()\n\u001b[1;32m--> 804\u001b[0m \u001b[39mfor\u001b[39;00m split_generator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager):\n\u001b[0;32m    805\u001b[0m   \u001b[39mif\u001b[39;00m splits_lib\u001b[39m.\u001b[39mSplit\u001b[39m.\u001b[39mALL \u001b[39m==\u001b[39m split_generator\u001b[39m.\u001b[39msplit_info\u001b[39m.\u001b[39mname:\n\u001b[0;32m    806\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    807\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtfds.Split.ALL is a special split keyword corresponding to the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39munion of all splits, so cannot be used as key in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    809\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m._split_generator().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\image\\flowers.py:67\u001b[0m, in \u001b[0;36mTFFlowers._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_split_generators\u001b[39m(\u001b[39mself\u001b[39m, dl_manager):\n\u001b[1;32m---> 67\u001b[0m   path \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload_and_extract(_URL)\n\u001b[0;32m     69\u001b[0m   \u001b[39m# There is no predefined train/val/test split for this dataset.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m   \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m     71\u001b[0m       tfds\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39mSplitGenerator(\n\u001b[0;32m     72\u001b[0m           name\u001b[39m=\u001b[39mtfds\u001b[39m.\u001b[39mSplit\u001b[39m.\u001b[39mTRAIN,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m           }),\n\u001b[0;32m     77\u001b[0m   ]\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:359\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_downloader\u001b[39m.\u001b[39mtqdm():\n\u001b[0;32m    358\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extractor\u001b[39m.\u001b[39mtqdm():\n\u001b[1;32m--> 359\u001b[0m     \u001b[39mreturn\u001b[39;00m _map_promise(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_extract, url_or_urls)\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:395\u001b[0m, in \u001b[0;36m_map_promise\u001b[1;34m(map_fn, all_inputs)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m all_promises \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mmap_nested(map_fn, all_inputs)  \u001b[39m# Apply the function\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m res \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mmap_nested(_wait_on_promise, all_promises)\n\u001b[0;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:143\u001b[0m, in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[0;32m    141\u001b[0m       \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(mapped)\n\u001b[0;32m    142\u001b[0m \u001b[39m# Singleton\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m function(data_struct)\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:379\u001b[0m, in \u001b[0;36m_wait_on_promise\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wait_on_promise\u001b[39m(p):\n\u001b[1;32m--> 379\u001b[0m   \u001b[39mreturn\u001b[39;00m p\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\promise\\promise.py:512\u001b[0m, in \u001b[0;36mPromise.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    510\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target()\n\u001b[0;32m    511\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait(timeout \u001b[39mor\u001b[39;00m DEFAULT_TIMEOUT)\n\u001b[1;32m--> 512\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_target_settled_value(_raise\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\promise\\promise.py:516\u001b[0m, in \u001b[0;36mPromise._target_settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_target_settled_value\u001b[39m(\u001b[39mself\u001b[39m, _raise\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[39m# type: (bool) -> Any\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_target()\u001b[39m.\u001b[39;49m_settled_value(_raise)\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\promise\\promise.py:226\u001b[0m, in \u001b[0;36mPromise._settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mif\u001b[39;00m _raise:\n\u001b[0;32m    225\u001b[0m     raise_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fulfillment_handler0\n\u001b[1;32m--> 226\u001b[0m     reraise(\u001b[39mtype\u001b[39;49m(raise_val), raise_val, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_traceback)\n\u001b[0;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fulfillment_handler0\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m    718\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 719\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[0;32m    720\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\promise\\promise.py:844\u001b[0m, in \u001b[0;36m_process_future_result.<locals>.handle_future_result\u001b[1;34m(future)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandle_future_result\u001b[39m(future):\n\u001b[0;32m    842\u001b[0m     \u001b[39m# type: (Any) -> None\u001b[39;00m\n\u001b[0;32m    843\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 844\u001b[0m         resolve(future\u001b[39m.\u001b[39;49mresult())\n\u001b[0;32m    845\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    846\u001b[0m         tb \u001b[39m=\u001b[39m exc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow_datasets\\core\\download\\extractor.py:99\u001b[0m, in \u001b[0;36m_Extractor._sync_extract\u001b[1;34m(self, from_path, method, to_path)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(to_path):\n\u001b[0;32m     98\u001b[0m   tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mrmtree(to_path)\n\u001b[1;32m---> 99\u001b[0m tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mgfile\u001b[39m.\u001b[39;49mrename(to_path_tmp, to_path)\n\u001b[0;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pbar_path\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[39mreturn\u001b[39;00m to_path\n",
      "File \u001b[1;32mc:\\Users\\jn_fe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:620\u001b[0m, in \u001b[0;36mrename_v2\u001b[1;34m(src, dst, overwrite)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mio.gfile.rename\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    608\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrename_v2\u001b[39m(src, dst, overwrite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    609\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Rename or move a file / directory.\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \n\u001b[0;32m    611\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39m    errors.OpError: If the operation fails.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m   _pywrap_file_io\u001b[39m.\u001b[39;49mRenameFile(\n\u001b[0;32m    621\u001b[0m       compat\u001b[39m.\u001b[39;49mpath_to_bytes(src), compat\u001b[39m.\u001b[39;49mpath_to_bytes(dst), overwrite)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe8 in position 369: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "data , info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)\n",
    "info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
