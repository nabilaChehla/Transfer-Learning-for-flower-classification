{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import vgg16\n",
    "import random\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import dataset to get train + validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "if os.path.exists('data_exist.txt'):\n",
    "    with open('data_exist.txt', 'r') as file:\n",
    "        # Read and print the contents of the file\n",
    "        file_contents = file.read().strip()\n",
    "        if file_contents:  # Check if the file is not empty\n",
    "            PATH = file_contents\n",
    "            print(PATH)\n",
    "        else:\n",
    "            print(\"File is empty.\")\n",
    "else:\n",
    "    dataset_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "    # Download and extract the dataset to the specified directory\n",
    "    path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=dataset_url, extract=True)\n",
    "    PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "    \n",
    "    # Write the PATH to the file\n",
    "    with open('data_exist.txt', 'w') as file:\n",
    "        file.write(PATH)\n",
    "    \n",
    "    print('Dataset downloaded and PATH written to data_exist.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adding test set :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if test set directory doesnt exist yet : \n",
    "PATH_to_testSet = os.path.join(PATH, 'test')\n",
    "PATH_to_testSet_cat = os.path.join(PATH_to_testSet, 'cats')\n",
    "PATH_to_testSet_dog = os.path.join(PATH_to_testSet, 'dogs')\n",
    "\n",
    "\n",
    "# if we dont already have a test set \n",
    "if os.path.isdir(PATH_to_testSet) is False:\n",
    "    os.makedirs(PATH_to_testSet) # we create the path directory for test\n",
    "    os.makedirs(PATH_to_testSet_cat) # we create the path directory test/cat\n",
    "    os.makedirs(PATH_to_testSet_dog) # we create the path directory test/cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to devide validation data to 50% test and 50% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_half_random_elements(source_directory, destination_directory):\n",
    "    # Check if the source directory exists\n",
    "    if not os.path.exists(source_directory):\n",
    "        return f\"Source directory '{source_directory}' does not exist.\"\n",
    "\n",
    "    if os.listdir(destination_directory):\n",
    "        return f\"destination directory '{destination_directory}' is not empty.\"\n",
    "    \n",
    "    # Check if the destination directory exists; if not, create it\n",
    "    if not os.path.exists(destination_directory):\n",
    "        os.makedirs(destination_directory)\n",
    "\n",
    "    # List all files and directories in the source directory\n",
    "    elements = os.listdir(source_directory)\n",
    "\n",
    "    # Randomly select half of the elements\n",
    "    num_elements_to_move = len(elements) // 2\n",
    "    elements_to_move = random.sample(elements, num_elements_to_move)\n",
    "\n",
    "    # Move the selected elements to the destination directory\n",
    "    for element in elements_to_move:\n",
    "        source_path = os.path.join(source_directory, element)\n",
    "        destination_path = os.path.join(destination_directory, element)\n",
    "        shutil.move(source_path, destination_path)\n",
    "\n",
    "    return f\"Moved {num_elements_to_move} random elements from '{source_directory}' to '{destination_directory}'.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calling the function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_to_validation_cats= os.path.join(PATH, 'validation/cats')\n",
    "PATH_to_validation_dogs= os.path.join(PATH, 'validation/dogs')\n",
    "\n",
    "print(move_half_random_elements(PATH_to_validation_cats, PATH_to_testSet_cat))\n",
    "print(move_half_random_elements(PATH_to_validation_dogs, PATH_to_testSet_dog))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Image preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_to_validation = os.path.dirname(PATH_to_validation_cats)\n",
    "PATH_to_trainSet = os.path.join(PATH, 'train')\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n",
    "    directory=PATH_to_trainSet,target_size=(224,224),classes=['cats','dogs'],batch_size=10)\n",
    "\n",
    "validation_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n",
    "    directory=PATH_to_validation,target_size=(224,224),classes=['cats','dogs'],batch_size=10)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n",
    "    directory=PATH_to_testSet,target_size=(224,224),classes=['cats','dogs'],batch_size=10, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images , lable = next(train_batches)\n",
    "rows=2\n",
    "cols = 2\n",
    "img_count = 0\n",
    "\n",
    "def plotImg(img_arr):\n",
    "    fig, axes = plt.subplots(1,10, figsize=(20,20))\n",
    "    axes=axes.flatten()\n",
    "    for img ,ax in zip(img_arr, axes):\n",
    "      ax.imshow(img)\n",
    "      ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotImg(images)\n",
    "print(lable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
