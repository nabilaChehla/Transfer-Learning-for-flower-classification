{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRNYcgy9f_fG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import vgg16\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import Sequential\n",
        "from keras.layers import Flatten , Dense\n",
        "import random\n",
        "import shutil\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N48246gRf_fK"
      },
      "source": [
        "## 1. Import dataset to get train + validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDoQd3Vcf_fM",
        "outputId": "7f0a4bd1-2701-401d-836a-8a9755bac976"
      },
      "outputs": [],
      "source": [
        "# Check if the file exists\n",
        "if os.path.exists('data_exist.txt'):\n",
        "    with open('data_exist.txt', 'r') as file:\n",
        "        # Read and print the contents of the file\n",
        "        file_contents = file.read().strip()\n",
        "        if file_contents:  # Check if the file is not empty\n",
        "            PATH = file_contents\n",
        "            print(PATH)\n",
        "        else:\n",
        "            print(\"File is empty.\")\n",
        "else:\n",
        "    dataset_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "    # Download and extract the dataset to the specified directory\n",
        "    path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=dataset_url, extract=True)\n",
        "    PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "    # Write the PATH to the file\n",
        "    with open('data_exist.txt', 'w') as file:\n",
        "        file.write(PATH)\n",
        "\n",
        "    print('Dataset downloaded and PATH written to data_exist.txt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDltUaMuf_fP"
      },
      "source": [
        "## 2. Adding test set :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhw3F-Rrf_fQ"
      },
      "outputs": [],
      "source": [
        "# check if test set directory doesnt exist yet :\n",
        "PATH_to_testSet = os.path.join(PATH, 'test')\n",
        "PATH_to_testSet_cat = os.path.join(PATH_to_testSet, 'cats')\n",
        "PATH_to_testSet_dog = os.path.join(PATH_to_testSet, 'dogs')\n",
        "\n",
        "\n",
        "# if we dont already have a test set\n",
        "if os.path.isdir(PATH_to_testSet) is False:\n",
        "    os.makedirs(PATH_to_testSet) # we create the path directory for test\n",
        "    os.makedirs(PATH_to_testSet_cat) # we create the path directory test/cat\n",
        "    os.makedirs(PATH_to_testSet_dog) # we create the path directory test/cat\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWq7Fyrgf_fR"
      },
      "source": [
        "### function to devide validation data to 50% test and 50% validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZbXOihjf_fR"
      },
      "outputs": [],
      "source": [
        "def move_half_random_elements(source_directory, destination_directory):\n",
        "    # Check if the source directory exists\n",
        "    if not os.path.exists(source_directory):\n",
        "        return f\"Source directory '{source_directory}' does not exist.\"\n",
        "\n",
        "    if os.listdir(destination_directory):\n",
        "        return f\"destination directory '{destination_directory}' is not empty.\"\n",
        "\n",
        "    # Check if the destination directory exists; if not, create it\n",
        "    if not os.path.exists(destination_directory):\n",
        "        os.makedirs(destination_directory)\n",
        "\n",
        "    # List all files and directories in the source directory\n",
        "    elements = os.listdir(source_directory)\n",
        "\n",
        "    # Randomly select half of the elements\n",
        "    num_elements_to_move = len(elements) // 2\n",
        "    elements_to_move = random.sample(elements, num_elements_to_move)\n",
        "\n",
        "    # Move the selected elements to the destination directory\n",
        "    for element in elements_to_move:\n",
        "        source_path = os.path.join(source_directory, element)\n",
        "        destination_path = os.path.join(destination_directory, element)\n",
        "        shutil.move(source_path, destination_path)\n",
        "\n",
        "    return f\"Moved {num_elements_to_move} random elements from '{source_directory}' to '{destination_directory}'.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCsUcanWf_fS"
      },
      "source": [
        "### calling the function :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysllgkGOf_fT",
        "outputId": "859d44a8-0c9a-4e41-cdcc-7f7c0d98fcc1"
      },
      "outputs": [],
      "source": [
        "\n",
        "PATH_to_validation_cats= os.path.join(PATH, 'validation/cats')\n",
        "PATH_to_validation_dogs= os.path.join(PATH, 'validation/dogs')\n",
        "\n",
        "print(move_half_random_elements(PATH_to_validation_cats, PATH_to_testSet_cat))\n",
        "print(move_half_random_elements(PATH_to_validation_dogs, PATH_to_testSet_dog))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHvSoErxf_fU"
      },
      "source": [
        "# 3. Image preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUim2SDGf_fU",
        "outputId": "b82af59f-c456-4401-b992-f547668fbbf3"
      },
      "outputs": [],
      "source": [
        "PATH_to_validation = os.path.dirname(PATH_to_validation_cats)\n",
        "PATH_to_trainSet = os.path.join(PATH, 'train')\n",
        "image_h = 224\n",
        "image_w = 224\n",
        "image_c = 3\n",
        "image_shape=(image_h,image_w,image_c)\n",
        "\n",
        "train_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n",
        "    directory=PATH_to_trainSet,target_size=(image_h,image_w),classes=['cats','dogs'],batch_size=10)\n",
        "\n",
        "validation_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n",
        "    directory=PATH_to_validation,target_size=(image_h,image_w),classes=['cats','dogs'],batch_size=10)\n",
        "\n",
        "test_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n",
        "    directory=PATH_to_testSet,target_size=(image_h,image_w),classes=['cats','dogs'],batch_size=10, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhhIIUvEf_fV"
      },
      "source": [
        "##  4. Visualize the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "X03ZdOprf_fV",
        "outputId": "9c509253-6c9c-442c-8fa7-f4daa9e0387c"
      },
      "outputs": [],
      "source": [
        "images , lable = next(train_batches)\n",
        "rows=2\n",
        "cols = 2\n",
        "img_count = 0\n",
        "\n",
        "def plotImg(img_arr):\n",
        "    fig, axes = plt.subplots(1,10, figsize=(20,20))\n",
        "    axes=axes.flatten()\n",
        "    for img ,ax in zip(img_arr, axes):\n",
        "      ax.imshow(img)\n",
        "      ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plotImg(images)\n",
        "print(lable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtQ67uSHf_fW"
      },
      "source": [
        "## Using transfer learning:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APxTJLg6f_fW"
      },
      "source": [
        "### Build fine-tuned vgg16 model :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1i73TVjf_fW"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained VGG16 model without the top (output) layer\n",
        "base_model = VGG16( weights='imagenet')\n",
        "\n",
        "# Define the input shape based on the last layer of the base model\n",
        "input_shape = base_model.layers[-1].output_shape[1:]\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:-1]:\n",
        "  model.add(layer)\n",
        "\n",
        "# the layers from vgg16 model shoud not be trainble\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "model.add(Dense(units=2,activation='linear',name='outputLayer'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm9xOUtVgoO4",
        "outputId": "e28d5fb9-985f-421f-fe3d-c12be2a98e15"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
